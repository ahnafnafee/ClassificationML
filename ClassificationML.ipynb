{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "06bd6e6bb8b1a59ff9a8fa9390517002ce8a147f96d75124d9423e09c7a6bc86"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### Q2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from cv2 import VideoWriter, VideoWriter_fourcc\n",
    "import matplotlib.cm as cm\n",
    "from collections import Counter\n",
    "import glob\n",
    "from matplotlib.image import imread\n",
    "from enum import Enum\n",
    "from scipy.linalg import svd\n",
    "import scipy.stats as ss\n",
    "import collections\n",
    "\n",
    "# For testing\n",
    "import sklearn\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "imp_data = np.genfromtxt('spambase.data', delimiter=',')\n",
    "\n",
    "def train_test_split(data, train_size, random_state):\n",
    "    '''Splitting testing and training data'''\n",
    "\n",
    "    # Resetting random seed\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    n = len(data)\n",
    "\n",
    "    # Rows shuffled\n",
    "    np.random.shuffle(data)\n",
    "\n",
    "    # Calculates array index for splitting\n",
    "    spltIdx = int(np.ceil((2/3)*n))\n",
    "\n",
    "    # Training-validation data split\n",
    "    data_train, data_test = data[:spltIdx,:], data[spltIdx:,:]\n",
    "\n",
    "    # Training data\n",
    "    x_tr, y_tr = np.hsplit(data_train, [-1])\n",
    "    # Testing Data\n",
    "    x_tt, y_tt = np.hsplit(data_test, [-1])\n",
    "\n",
    "\n",
    "\n",
    "    # Separating class label from data\n",
    "    class_label_tr = data_train[:, -1].astype(int)\n",
    "    dataset_tr = data_train[:, :-1]\n",
    "\n",
    "    class_label_tt = data_test[:, -1].astype(int)\n",
    "    dataset_tt = data_test[:, :-1]\n",
    "\n",
    "    # Filtering features with low std\n",
    "    # dataset_tr = std_filter1(dataset_tr, 0)\n",
    "    # dataset_tt = std_filter1(dataset_tt, 0)\n",
    "\n",
    "    og_mean = np.mean(dataset_tr)\n",
    "    og_std = np.std(dataset_tr)\n",
    "\n",
    "    # dataset_tr = (dataset_tr - np.mean(dataset_tr)) / np.std(dataset_tr)\n",
    "    # dataset_tt = (dataset_tt - np.mean(dataset_tt)) / np.std(dataset_tt)\n",
    "\n",
    "    dataset_tr = (dataset_tr - og_mean) / og_std\n",
    "    dataset_tt = (dataset_tt - og_mean) / og_std\n",
    "\n",
    "    # x_tr = (x_tr - np.mean(x_tr)) / np.std(x_tr)\n",
    "    # x_tt = (x_tt - np.mean(x_tt)) / np.std(x_tt)\n",
    "\n",
    "    # return x_tr, y_tr, x_tt, y_tt\n",
    "    return dataset_tr, class_label_tr, dataset_tt, class_label_tt\n",
    "    # return dataset_tr, y_tr, dataset_tt, y_tt\n",
    "\n",
    "\n",
    "def std_filter(data, std_val):\n",
    "    '''Filters out features with low std'''\n",
    "\n",
    "    dataset = np.copy(data)\n",
    "    temp = 0\n",
    "    while temp < dataset.shape[1]:\n",
    "        if(np.std(dataset[:,temp]) == 0):\n",
    "            dataset = np.delete(dataset, temp, 1)\n",
    "            temp = temp - 1\n",
    "        else:\n",
    "            dataset[:,temp] = (dataset[:,temp] - np.mean(dataset[:,temp])) / np.std(dataset[:,temp])\n",
    "            temp = temp + 1\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierEvaluation:\n",
    "    def __init__(self, y_true, y_pred):\n",
    "        self.y_true = y_true.astype(int)\n",
    "        self.y_pred = y_pred.astype(int)\n",
    "        unique, counts = np.unique(y_true, return_counts=True)\n",
    "        self.y_true_dict = dict(zip(unique, counts))\n",
    "        unique, counts = np.unique(y_pred, return_counts=True)\n",
    "        self.y_pred_dict = dict(zip(unique, counts))\n",
    "        \n",
    "\n",
    "    def eval(self):\n",
    "        self.TP = 0\n",
    "        self.TN = 0\n",
    "        self.FP = 0\n",
    "        self.FN = 0\n",
    "\n",
    "        for i in range(len(self.y_true)):\n",
    "            if (self.y_true[i] == 1 and self.y_pred[i] == 1):\n",
    "                self.TP += 1\n",
    "            elif (self.y_true[i] == 1 and self.y_pred[i] == 0):\n",
    "                self.FP += 1\n",
    "            elif (self.y_true[i] == 0 and self.y_pred[i] == 1):\n",
    "                self.FN += 1\n",
    "            elif (self.y_true[i] == 0 and self.y_pred[i] == 0):\n",
    "                self.TN += 1\n",
    "            \n",
    "\n",
    "    def get_precision(self):\n",
    "        '''Precision = TP / (TP + FP)'''\n",
    "        \n",
    "        precision = self.TP/(self.TP + self.FP)\n",
    "        return precision\n",
    "\n",
    "    def get_recall(self):\n",
    "        '''Precision = TP / (TP + FN)'''\n",
    "\n",
    "        recall = self.TP/(self.TP + self.FN)\n",
    "        return recall\n",
    "\n",
    "    def get_fmeasure(self):\n",
    "        '''Recall = (2 * Precision * Recall) / (Precision + Recall)'''\n",
    "\n",
    "        fmeasure = (2 * self.get_precision() * self.get_recall())/(self.get_precision() + self.get_recall())\n",
    "        return fmeasure\n",
    "\n",
    "    def get_accuracy(self):\n",
    "        '''Accuracy = (TP + TN) / (TP + TN + FP + FN)'''\n",
    "\n",
    "        accuracy = (self.TP + self.TN) /(self.TP + self.TN + self.FP + self.FN)\n",
    "\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self, x, y):\n",
    "        self.n_samples, self.n_features = x.shape\n",
    "        self.classes = np.unique(y)\n",
    "        self.n_classes = len(self.classes)\n",
    "        self.features = x\n",
    "        self.target = y.flatten()\n",
    "        \n",
    "        self.mean_data = np.zeros((self.n_classes, self.n_features), dtype=np.float64)\n",
    "        self.std_data = np.zeros((self.n_classes, self.n_features), dtype=np.float64)\n",
    "        self.prior_data = np.zeros(self.n_classes)\n",
    "        \n",
    "\n",
    "    def get_target(self):\n",
    "        '''For debugging purposes'''\n",
    "\n",
    "        print(np.mean(self.mean_data.flatten()))\n",
    "        print(np.mean(self.std_data.flatten()))\n",
    "        print(self.target.shape)\n",
    "        print(self.features.shape)\n",
    "        return self.target\n",
    "\n",
    "\n",
    "    def fit(self):\n",
    "        '''Separates spam and not spam rows'''\n",
    "\n",
    "        data = self.features\n",
    "        label = self.target\n",
    "\n",
    "        label = label.reshape(label.shape[0], 1)\n",
    "\n",
    "        spIdx_lst = np.where(~label.any(axis=1))[0]\n",
    "        notIdx_sp_lst = np.where(label.any(axis=1))[0]\n",
    "\n",
    "        d_list = data.tolist()\n",
    "        sp_list = []\n",
    "        not_sp_list = []\n",
    "\n",
    "        for index in spIdx_lst:\n",
    "            sp_list += [d_list[index]]\n",
    "\n",
    "        for index in notIdx_sp_lst:\n",
    "            not_sp_list += [d_list[index]]\n",
    "\n",
    "\n",
    "        sp_data = np.asarray(sp_list)\n",
    "        not_sp_data = np.asarray(not_sp_list)\n",
    "\n",
    "\n",
    "        self.mean_data[0, :] = sp_data.mean(axis=0)\n",
    "        self.std_data[0, :] = sp_data.std(axis=0)\n",
    "        self.prior_data[0] = sp_data.shape[0] / float(self.n_samples)\n",
    "\n",
    "        self.mean_data[1, :] = not_sp_data.mean(axis=0)\n",
    "        self.std_data[1, :] = not_sp_data.std(axis=0)\n",
    "        self.prior_data[1] = not_sp_data.shape[0] / float(self.n_samples)\n",
    "\n",
    "\n",
    "    def get_stats(self):\n",
    "        '''For debugging purposes'''\n",
    "\n",
    "        return self.mean_data, self.std_data, self.prior_data\n",
    "\n",
    "\n",
    "    def calc_posterior(self, x):\n",
    "        '''Chooses the class label based on which class probability is higher'''\n",
    "\n",
    "        posteriors = []\n",
    "\n",
    "        for i in range(self.n_classes):\n",
    "            prior = self.prior_data[i]\n",
    "            n_pdf = self.norm_pdf(x, i)\n",
    "            n_pdf = np.prod(np.nan_to_num(n_pdf, nan=10^-8, posinf=10^8, neginf=10^-8))\n",
    "            posterior = prior * n_pdf\n",
    "            posteriors.append(posterior)\n",
    "        return self.classes[np.argmax(posteriors)]\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        '''Gets the predicted target values'''\n",
    "\n",
    "        preds = [self.calc_posterior(i) for i in x]\n",
    "        return np.asarray(preds, dtype=np.float64)\n",
    "\n",
    "\n",
    "    def norm_pdf(self, data, c_idx):\n",
    "        '''Calculates norm pdf'''\n",
    "\n",
    "        mean = self.mean_data[c_idx]\n",
    "        std = self.std_data[c_idx]\n",
    "\n",
    "        numerator = np.exp(- (data-mean)**2 / (2 * (std**2)))\n",
    "        denominator = std * np.sqrt(2 * np.pi)\n",
    "\n",
    "        return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Precision: 95.65217391304348%\nRecall: 67.85290628707%\nF-measure: 79.38931297709924%\nAccuracy: 80.62622309197651%\n"
     ]
    }
   ],
   "source": [
    "x_tr, y_tr, x_tt, y_tt = train_test_split(imp_data, train_size=2/3, random_state=0)\n",
    "\n",
    "# np.set_printoptions(threshold=sys.maxsize)\n",
    "# np.set_printoptions(threshold = False)\n",
    "\n",
    "g_nb = NaiveBayes(x_tr, y_tr)\n",
    "g_nb.fit()\n",
    "# print(g_nb.get_stats())\n",
    "predictions = g_nb.predict(x_tt)\n",
    "gb_ce = ClassifierEvaluation(y_tt, predictions)\n",
    "gb_ce.eval()\n",
    "print(f\"Precision: {gb_ce.get_precision() * 100}%\")\n",
    "print(f\"Recall: {gb_ce.get_recall() * 100}%\")\n",
    "print(f\"F-measure: {gb_ce.get_fmeasure() * 100}%\")\n",
    "print(f\"Accuracy: {gb_ce.get_accuracy() * 100}%\")"
   ]
  },
  {
   "source": [
    "### Q3"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-3-c2f7a623ccc8>:60: RuntimeWarning: divide by zero encountered in log\n",
      "  sub_logA = np.nan_to_num(np.log(1-A), nan=10^-8, posinf=10^8, neginf=10^-12)\n",
      "EPOCH: 10000\n",
      "EPOCH: 20000\n",
      "EPOCH: 30000\n",
      "EPOCH: 40000\n",
      "EPOCH: 50000\n",
      "EPOCH: 60000\n",
      "EPOCH: 70000\n",
      "EPOCH: 80000\n",
      "EPOCH: 90000\n",
      "EPOCH: 100000\n",
      "Precision: 43.92361111111111%\n",
      "Recall: 77.37003058103976%\n",
      "F-measure: 56.03543743078626%\n",
      "Accuracy: 74.1030658838878%\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, lr=1):\n",
    "        self.lr = lr\n",
    "        self.precision = 10^-20\n",
    "        self.max_iters = 100000\n",
    "\n",
    "\n",
    "    def fit(self, x, y):\n",
    "\n",
    "        biasF = np.ones(((len(x)), 1))\n",
    "        x = np.hstack((biasF, x))\n",
    "        \n",
    "        self.features = x.T\n",
    "        self.target = y.T\n",
    "        self.target = self.target.reshape(1, self.target.shape[0])\n",
    "        n, m = self.features.shape\n",
    "\n",
    "\n",
    "        self.W = np.zeros((n, 1))\n",
    "        cost = 0\n",
    "        step_size_c = 1\n",
    "        c_change = 0\n",
    "        epoch = 0\n",
    "\n",
    "        # while step_size_c > self.precision:\n",
    "        for i in range(self.max_iters):\n",
    "        \n",
    "            Z = np.dot(self.W.T, self.features)\n",
    "            A = self.sigmoid(Z)\n",
    "\n",
    "            prev_cost = cost\n",
    "            cost = self.cost_func(m, A, self.target)\n",
    "\n",
    "            prev_change = c_change\n",
    "            c_change = abs(cost - prev_cost)\n",
    "\n",
    "            if c_change > prev_change:\n",
    "                self.lr = self.lr/2\n",
    "\n",
    "            dW = (1/m)*np.dot(A - self.target, self.features.T)\n",
    "            \n",
    "            self.W = self.W - self.lr * dW.T\n",
    "\n",
    "            step_size_c = abs(c_change)\n",
    "            epoch += 1\n",
    "\n",
    "            if epoch % 10000 == 0:\n",
    "                print(\"EPOCH:\", epoch)\n",
    "\n",
    "\n",
    "    def gradient_ascent(self, X, h, y):\n",
    "        return np.dot(X.T, y - h)\n",
    "\n",
    "    def cost_func(self, m, A, Y):\n",
    "\n",
    "        Y = np.nan_to_num(Y, nan=10^-8, posinf=10^8, neginf=10^-12)\n",
    "        A = np.nan_to_num(A, nan=10^-8, posinf=10^8, neginf=10^-12)\n",
    "        sub_logA = np.nan_to_num(np.log(1-A), nan=10^-8, posinf=10^8, neginf=10^-12)\n",
    "        sub_Y = np.nan_to_num(1 - Y, nan=10^-8, posinf=10^8, neginf=10^-12)\n",
    "\n",
    "        cost = -(1/m)*np.sum( Y * np.log(A) + sub_Y * sub_logA)\n",
    "        return cost\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "\n",
    "        biasF = np.ones(((len(x)), 1))\n",
    "        x = np.hstack((biasF, x))\n",
    "\n",
    "        x = x.T\n",
    "        n, m = x.shape\n",
    "        \n",
    "        Z = np.dot(self.W.T, x)\n",
    "        A = self.sigmoid(Z)\n",
    "        A = A > 0.5\n",
    "        return np.array(A, dtype = 'int64').flatten()\n",
    "\n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1 + np.exp(- x))\n",
    "\n",
    "\n",
    "    def get_stats(self):\n",
    "        return self.features\n",
    "\n",
    "\n",
    "x_tr, y_tr, x_tt, y_tt = train_test_split(imp_data, train_size=2/3, random_state=0)\n",
    "\n",
    "# np.set_printoptions(threshold=sys.maxsize)\n",
    "np.set_printoptions(threshold = False)\n",
    "\n",
    "g_lr = LogisticRegression()\n",
    "g_lr.fit(x_tr, y_tr)\n",
    "predictions = g_lr.predict(x_tt)\n",
    "lr_ce = ClassifierEvaluation(y_tt, predictions)\n",
    "lr_ce.eval()\n",
    "print(f\"Precision: {lr_ce.get_precision() * 100}%\")\n",
    "print(f\"Recall: {lr_ce.get_recall() * 100}%\")\n",
    "print(f\"F-measure: {lr_ce.get_fmeasure() * 100}%\")\n",
    "print(f\"Accuracy: {lr_ce.get_accuracy() * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "I f****** give up\n"
     ]
    }
   ],
   "source": [
    "print(\"I f****** give up\")"
   ]
  },
  {
   "source": [
    "### Q1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 1.75949201 -0.74870233]\n [ 0.06547994 -0.73933973]]\n[[0.33151634 0.00688534]\n [0.52104341 0.00759711]]\n[0.4 0.6]\n\n[[ 0.80137336 -0.7310336 ]\n [-0.26967943 -0.73759107]\n [ 1.42797567 -0.75558767]\n [-0.3352541  -0.74939451]\n [ 2.09100835 -0.74181699]]\n[[ 0.9908112  -0.73919404]]\n"
     ]
    }
   ],
   "source": [
    "imp_data = np.genfromtxt('q1_2.csv', delimiter=',')\n",
    "\n",
    "x_tr, y_tr = np.hsplit(imp_data, [-1])\n",
    "og_mean = np.mean(x_tr)\n",
    "og_std = np.std(x_tr)\n",
    "x = (x_tr - og_mean) / og_std\n",
    "\n",
    "label = y_tr\n",
    "n_samples, n_features = x.shape\n",
    "classes = np.unique(y_tr)\n",
    "n_classes = len(classes)\n",
    "\n",
    "mean_data = np.zeros((n_classes, n_features), dtype=np.float64)\n",
    "std_data = np.zeros((n_classes, n_features), dtype=np.float64)\n",
    "prior_data = np.zeros(n_classes)\n",
    "label = label.reshape(label.shape[0], 1)\n",
    "\n",
    "noIdx_lst = np.where(~label.any(axis=1))[0]\n",
    "yesIdx_lst = np.where(label.any(axis=1))[0]\n",
    "\n",
    "\n",
    "d_list = x.tolist()\n",
    "no_list = []\n",
    "yes_list = []\n",
    "\n",
    "for index in noIdx_lst:\n",
    "    no_list += [d_list[index]]\n",
    "\n",
    "for index in yesIdx_lst:\n",
    "    yes_list += [d_list[index]]\n",
    "\n",
    "\n",
    "no_data = np.asarray(no_list)\n",
    "yes_data = np.asarray(yes_list)\n",
    "\n",
    "\n",
    "mean_data[0, :] = no_data.mean(axis=0)\n",
    "std_data[0, :] = no_data.std(axis=0)\n",
    "prior_data[0] = no_data.shape[0] / float(n_samples)\n",
    "\n",
    "mean_data[1, :] = yes_data.mean(axis=0)\n",
    "std_data[1, :] = yes_data.std(axis=0)\n",
    "prior_data[1] = yes_data.shape[0] / float(n_samples)\n",
    "\n",
    "print(mean_data)\n",
    "print(std_data)\n",
    "print(prior_data)\n",
    "print()\n",
    "print(x)\n",
    "\n",
    "x_tt = np.asarray([[242, 4.56]], dtype=np.float32)\n",
    "x_test = (x_tt - og_mean) / og_std\n",
    "print(x_test)\n",
    "\n",
    "\n",
    "\n",
    "# x_tr, y_tr, x_tt, y_tt = train_test_split(imp_data, train_size=3/3, random_state=0)\n",
    "\n",
    "# # np.set_printoptions(threshold=sys.maxsize)\n",
    "# # np.set_printoptions(threshold = False)\n",
    "\n",
    "# g_nb = NaiveBayes(x_tr, y_tr)\n",
    "# g_nb.fit()\n",
    "# g_nb.get_stats()\n",
    "# # print(g_nb.get_stats())\n",
    "# predictions = g_nb.predict(x_tt)\n",
    "# gb_ce = ClassifierEvaluation(y_tt, predictions)\n",
    "# gb_ce.eval()\n",
    "# print(f\"Precision: {gb_ce.get_precision() * 100}%\")\n",
    "# print(f\"Recall: {gb_ce.get_recall() * 100}%\")\n",
    "# print(f\"F-measure: {gb_ce.get_fmeasure() * 100}%\")\n",
    "# print(f\"Accuracy: {gb_ce.get_accuracy() * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}